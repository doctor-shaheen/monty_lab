{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tbp.monty.frameworks.environments.ycb import YCBMeshDataset\n",
    "import trimesh\n",
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#from nupic.research.frameworks.htm.temporal_memory import PairMemoryApicalTiebreak\n",
    "from nupic.research.frameworks.columns import ApicalTiebreakPairMemory\n",
    "\n",
    "#from scipy import sparse\n",
    "#from scipy.sparse import csc_array, csr_array, coo_array\n",
    "\n",
    "import pickle\n",
    "\n",
    "import os, sys, inspect\n",
    "sys.path.insert(1, os.path.expanduser(\"~/tbp/tbp.monty/projects/temporal_memory\"))\n",
    "\n",
    "from data_utils import *\n",
    "from train import *\n",
    "\n",
    "dataset = YCBMeshDataset(os.path.expanduser(\"~/tbp/data/habitat/objects/ycb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt \n",
    "\n",
    "fig, axes = plt.subplots(4, 5, figsize=(15, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(20):\n",
    "    axes[i].hist(curvatures[i], bins='auto')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def test_loop(object_id, train_active, train_objects, curve_hash_radius, curve_clusters, coord_hash_radius):\n",
    "    curvatures, coordinates = get_test_data(object_id, curve_hash_radius=curve_hash_radius, curve_clusters=curve_clusters, coord_hash_radius=coord_hash_radius, num_samples=curve_clusters)\n",
    "\n",
    "    testing_active_cells = []\n",
    "\n",
    "    for curv, coord in zip(curvatures, coordinates):\n",
    "        tm.compute(\n",
    "            activeColumns=curv,\n",
    "            basalInput=coord,\n",
    "            learn=False\n",
    "        )\n",
    "\n",
    "        testing_active_cells.append(set(tm.getActiveCells().tolist()))\n",
    "\n",
    "    \"\"\"\n",
    "    plot heatmap to describe overlap between training observations and testing observation\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(ncols=len(train_objects), figsize=(10, 10))\n",
    "\n",
    "    if not isinstance(axes, np.ndarray):\n",
    "        axes = np.array([axes], dtype=\"O\")\n",
    "\n",
    "    mat = np.zeros((len(train_objects), len(testing_active_cells), len(train_active[0])))\n",
    "\n",
    "    for t in range(len(train_objects)):\n",
    "        for i in range(len(train_active[t])):\n",
    "            for j in range(len(testing_active_cells)):\n",
    "                #if i < j:\n",
    "                if len(overlap(train_active[t][i], testing_active_cells[j])) > 20:\n",
    "                    mat[t, j, i] = len(overlap(train_active[t][i], testing_active_cells[j]))\n",
    "\n",
    "        sns.heatmap(mat[t, :], ax=axes[t], cbar=(t == (len(train_objects) - 1)))\n",
    "        axes[t].set_xlabel(\"\\nTrain Obj {0}\".format(train_objects[t]))\n",
    "        axes[t].set_title(\"{0}\".format(int(mat[t, :].sum())))\n",
    "\n",
    "        if t == 0:\n",
    "            axes[t].set_ylabel(\"Inference Obj {0}\\n\".format(object_id))\n",
    "    \n",
    "    fig.suptitle(\"OBJECT {0}: INFERENCE. \\n\\nPREDICTED OBJECT: {1}\".format(object_id, train_objects[mat.reshape(len(train_objects), -1).sum(axis=1).argmax()]))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "setup\n",
    "\"\"\"\n",
    "\n",
    "proximal_n = 2048\n",
    "proximal_w = 30\n",
    "\n",
    "basal_n = 2048\n",
    "basal_w = 30\n",
    "\n",
    "apical_n = 2048\n",
    "apical_w = 30\n",
    "\n",
    "tm = ApicalTiebreakPairMemory(\n",
    "    columnCount=proximal_n,\n",
    "    basalInputSize=basal_n,\n",
    "    apicalInputSize=apical_n,\n",
    "    cellsPerColumn=5, \n",
    "    activationThreshold=25,#10, \n",
    "    reducedBasalThreshold=25,#10,\n",
    "    initialPermanence=0.51,\n",
    "    connectedPermanence=0.5,\n",
    "    minThreshold=25,#10,\n",
    "    sampleSize=30,\n",
    "    permanenceIncrement=0.1,\n",
    "    permanenceDecrement=0.02,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "training\n",
    "\"\"\"\n",
    "train_objects = [5, 6, 7, 8, 9, 10]\n",
    "#train_objects = list(range(20))\n",
    "\n",
    "curve_hash_radius = 500\n",
    "coord_hash_radius = 5\n",
    "curve_clusters = 200\n",
    "\n",
    "train_active = []\n",
    "\n",
    "#for t in train_objects:\n",
    "#    train_active.append(train_loop(t, curve_hash_radius=curve_hash_radius, curve_clusters=curve_clusters, coord_hash_radius=coord_hash_radius))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "testing\n",
    "\"\"\"\n",
    "\n",
    "for t in train_objects:\n",
    "    test_loop(t, train_active=train_active, train_objects=train_objects, curve_hash_radius=curve_hash_radius, curve_clusters=curve_clusters, coord_hash_radius=coord_hash_radius)\n",
    "\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_loop(object_id, percent=1.0, num_iter=1):\n",
    "#     curvatures, coordinates = get_data(object_id, percent)\n",
    "\n",
    "#     training_active_cells = []\n",
    "\n",
    "#     #for train_ind in range(0, len(curvatures), 2):\n",
    "#     for train_ind in range(len(curvatures)):\n",
    "#         if not len(curvatures[train_ind]):\n",
    "#             pass\n",
    "\n",
    "#         for _ in range(num_iter):\n",
    "#             tm.compute(\n",
    "#                 active_minicolumns=torch.from_numpy(curvatures[train_ind]),\n",
    "#                 basal_input=torch.from_numpy(get_object_id(object_id, basal_n, basal_w)),\n",
    "#                 apical_input=torch.from_numpy(coordinates[train_ind]),\n",
    "#                 learn=True\n",
    "#             )\n",
    "\n",
    "#         training_active_cells.append(set(tm.get_active_cells().tolist()))\n",
    "\n",
    "#     return training_active_cells\n",
    "\n",
    "# def train_loop_og(object_id, percent=1.0, num_iter=1):\n",
    "#     curvatures, coordinates = get_data(object_id, percent)\n",
    "\n",
    "#     training_active_cells = []\n",
    "\n",
    "#     #for train_ind in range(0, len(curvatures), 2):\n",
    "#     for train_ind in range(len(curvatures)):\n",
    "#         if not len(curvatures[train_ind]):\n",
    "#             pass\n",
    "\n",
    "#         for _ in range(num_iter):\n",
    "#             tm_og.compute(\n",
    "#                 activeColumns=curvatures[train_ind],\n",
    "#                 basalInput=get_object_id(object_id, basal_n, basal_w),\n",
    "#                 apicalInput=coordinates[train_ind],\n",
    "#                 learn=True\n",
    "#             )\n",
    "\n",
    "#         training_active_cells.append(set(tm_og.getActiveCells().tolist()))\n",
    "\n",
    "#     return training_active_cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# curvatures = proximal dendrites\n",
    "# basal input = object ID\n",
    "# apical input = location ID\n",
    "\n",
    "# tm = PairMemoryApicalTiebreak(\n",
    "#     num_minicolumns=proximal_n,\n",
    "#     basal_input_size=basal_n,\n",
    "#     apical_input_size=apical_n,\n",
    "#     num_cells_per_minicolumn=5,\n",
    "#     activation_threshold=10,\n",
    "#     reduced_basal_threshold=10,\n",
    "#     initial_permanence=0.5,\n",
    "#     connected_permanence=0.5,\n",
    "#     matching_threshold=10,\n",
    "#     sample_size=30,\n",
    "#     permanence_increment=0.1,\n",
    "#     permanence_decrement=0.02,\n",
    "#     basal_segment_incorrect_decrement=0.0,\n",
    "#     seed=42\n",
    "# )\n",
    "\n",
    "'''\n",
    "tm_og = ApicalTiebreakPairMemory(\n",
    "    columnCount=proximal_n,\n",
    "    basalInputSize=basal_n,\n",
    "    apicalInputSize=apical_n,\n",
    "    cellsPerColumn=5, # proximal_n * 5 = total cells\n",
    "    activationThreshold=10, # 15 out of 30\n",
    "    reducedBasalThreshold=10, # 15 out of 30\n",
    "    initialPermanence=0.21, # --> initialPermanence=0.5 if not learning on higher order sequences\n",
    "    connectedPermanence=0.5,\n",
    "    minThreshold=8, # matching threshold == activation threshold == reduced basal threshold\n",
    "    sampleSize=40, # at most w\n",
    "    permanenceIncrement=0.1,\n",
    "    permanenceDecrement=0.02,\n",
    "    seed=42\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "w = 105 out of n = 5000\n",
    "proximal SDR input: (# points x 5000) (curvatures)\n",
    "basal SDR input: (# points x 100) (object ID) <-- randomly generated (deterministic), 25 bits are ON of the 100 bits total\n",
    "apical SDR input: (# points x 5000) (locations)\n",
    "\n",
    "# points ~ 9000 - 16000\n",
    "\n",
    "- reduce w and n\n",
    "- w = 30, n = 2048\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basal connections: segments x (total # of possible synapses == total number of inputs bits == 100)\n",
    "\n",
    "tm_og.basalConnections.matrix.toDense().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apical connections: segments x (total # of possible synapses == total number of input bits == 5000)\n",
    "\n",
    "connections = tm_og.apicalConnections.matrix.toDense()\n",
    "\n",
    "#x, y = connections.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tm_og.apicalConnections.matrix.toDense()[0, :] != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a65c7def2fc82c630ec607efa90c20d772b9431074a1fce9bd8bb07bc24fb060"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
