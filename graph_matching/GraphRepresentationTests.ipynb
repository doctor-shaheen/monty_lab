{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4b034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tbp.monty.frameworks.models.object_model import ObjectModel\n",
    "from tbp.monty.frameworks.utils.logging_utils import load_stats\n",
    "from tbp.monty.frameworks.utils.plot_utils import plot_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e5a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0284c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_path = os.path.expanduser(\"~/tbp/results/monty/pretrained_models/\")\n",
    "pretrained_dict = pretrain_path + \"pretrained_ycb_v4/touch_1lm_10distinctobj/pretrained/\"\n",
    "log_path = os.path.expanduser(\"~/tbp/results/monty/projects/monty_runs/\")\n",
    "\n",
    "exp_name = \"evidence_tests_nomt/\"\n",
    "exp_path = log_path + exp_name\n",
    "\n",
    "save_path = exp_path + '/stepwise_examples/'\n",
    "train_stats, eval_stats, detailed_stats, lm_models = load_stats(exp_path,\n",
    "                                                                load_train=False,\n",
    "                                                                load_eval=True,\n",
    "                                                                load_detailed=False,\n",
    "                                                                pretrained_dict=pretrained_dict,\n",
    "                                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bbe805",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_id = 'mug'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99784b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(lm_models['pretrained'][0][object_id])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab9234",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ObjectModel(\n",
    "            object_id=object_id,\n",
    "            max_nodes=200,\n",
    "            max_size=0.1,  # 10cm\n",
    "            num_cells_per_dim=50,  # -> cell size = 1mm (0.001)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ade040",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_graph(lm_models['pretrained'][0][object_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1c08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da175a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model._location_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855e008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_count = model._observation_count\n",
    "print(obs_count.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925041e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(model._graph)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3a91d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(1,1,1,projection='3d')\n",
    "locs = model._location_grid\n",
    "loc_ids = np.where((locs!=0).all(axis=3))\n",
    "locs_to_use = locs[loc_ids]\n",
    "s = ax.scatter(locs_to_use[:,0],\n",
    "           locs_to_use[:,1],\n",
    "           locs_to_use[:,2],)\n",
    "#           c=obs_count[exists[0], exists[1], exists[2]])\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xticks([]), ax.set_yticks([]), ax.set_zticks([])\n",
    "fig.colorbar(s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9d47d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.subplot(1,1,1,projection='3d')\n",
    "exists = np.where(obs_count > 0)\n",
    "s = ax.scatter(exists[0],\n",
    "           exists[1],\n",
    "           exists[2],\n",
    "          c=obs_count[exists[0], exists[1], exists[2]])\n",
    "\n",
    "ax.set_aspect(\"equal\")\n",
    "# ax.set_xticks([]), ax.set_yticks([]), ax.set_zticks([])\n",
    "fig.colorbar(s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e29c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_feature = \"principal_curvatures_log\"\n",
    "feature_id = model.feature_mapping[\"patch\"][show_feature][0]\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(1,1,1,projection='3d')\n",
    "exists = np.where(obs_count > 0)\n",
    "locs = model._location_grid\n",
    "loc_ids = np.where((locs!=0).all(axis=3))\n",
    "locs_to_use = locs[loc_ids]\n",
    "s = ax.scatter(locs_to_use[:,0],\n",
    "           locs_to_use[:,1],\n",
    "           locs_to_use[:,2],\n",
    "              c=model._feature_grid[exists[0],exists[1],exists[2],feature_id],\n",
    "              cmap='seismic')\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xticks([]), ax.set_yticks([]), ax.set_zticks([])\n",
    "fig.colorbar(s)\n",
    "plt.title(show_feature)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32440b99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_feature = \"point_normal\"\n",
    "feature_id = model.feature_mapping[\"patch\"][show_feature][:3]\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(1,1,1,projection='3d')\n",
    "exists = np.where(obs_count > 0)\n",
    "locs = model._location_grid\n",
    "loc_ids = np.where((locs!=0).all(axis=3))\n",
    "locs_to_use = locs[loc_ids]\n",
    "s = ax.scatter(locs_to_use[:,0],\n",
    "           locs_to_use[:,1],\n",
    "           locs_to_use[:,2],)\n",
    "pn_len = 0.03\n",
    "for i, pn in enumerate(model._feature_grid[exists[0],exists[1],exists[2],feature_id[0]:feature_id[1]]): \n",
    "    plt.plot([locs_to_use[i,0], locs_to_use[i,0] + pn[0] * pn_len],\n",
    "            [locs_to_use[i,1], locs_to_use[i,1] + pn[1] * pn_len],\n",
    "            [locs_to_use[i,2], locs_to_use[i,2] + pn[2] * pn_len])\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xticks([]), ax.set_yticks([]), ax.set_zticks([])\n",
    "fig.colorbar(s)\n",
    "plt.title(show_feature)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c34cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_ids = feature_id = model.feature_mapping[\"patch\"][\"curvature_directions\"]\n",
    "pn_ids = feature_id = model.feature_mapping[\"patch\"][\"point_normal\"]\n",
    "cds = model._graph.x[0,cd_ids[0]:cd_ids[1]]\n",
    "cd1 = cds[:3]\n",
    "cd2 = cds[3:]\n",
    "pn = model._graph.x[0,pn_ids[0]:pn_ids[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6d7681",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # number of vectors\n",
    "# direction = np.array([1, 2, 3])  # direction in which most vectors point\n",
    "direction = cd1\n",
    "opposite_direction = -direction  # direction in which two vectors point\n",
    "\n",
    "# generate random vectors around the main direction\n",
    "vectors = np.random.randn(n-2, 3)*0.1 + direction\n",
    "vectors = vectors / np.linalg.norm(vectors, axis=1)[:, np.newaxis]\n",
    "\n",
    "# add two vectors in the opposite direction\n",
    "opposite_vectors = np.random.randn(4, 3) *0.1 + opposite_direction\n",
    "opposite_vectors = opposite_vectors / np.linalg.norm(opposite_vectors, axis=1)[:, np.newaxis]\n",
    "\n",
    "# combine all vectors\n",
    "vectors = np.concatenate([vectors, opposite_vectors], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8c59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260834ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = plt.subplot(1,1,1,projection='3d')\n",
    "for vec in vectors:\n",
    "    plt.plot([0,vec[0]], [0,vec[1]], [0,vec[2]], c='blue')\n",
    "ax.set_aspect(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49299059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unit_vector_mean(u_vecs):\n",
    "    \"\"\"Calculate the mean unit vector from a list of them.\"\"\"\n",
    "    mean = np.median(u_vecs,axis=0)\n",
    "    normed_mean = mean / np.linalg.norm(mean)\n",
    "    return normed_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe27b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75345be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def normalize(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0:\n",
    "        return v\n",
    "    return v / norm\n",
    "\n",
    "def unit_vector_mean2(vectors):\n",
    "    kmeans = KMeans(n_clusters=2).fit(vectors)\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    \n",
    "    # Find the average direction for each cluster\n",
    "    avg_dirs = [normalize(center) for center in cluster_centers]\n",
    "    \n",
    "    # Assign each vector to the cluster with the closest average direction\n",
    "    assigned_vectors = {0: [], 1: []}\n",
    "    for v in vectors:\n",
    "        distances = [np.dot(normalize(v), avg_dir) for avg_dir in avg_dirs]\n",
    "        cluster = np.argmax(distances)\n",
    "        assigned_vectors[cluster].append(v)\n",
    "    \n",
    "    # Average the vectors within each cluster with their corresponding average direction\n",
    "    cluster_avgs = []\n",
    "    for cluster, vecs in assigned_vectors.items():\n",
    "        aligned_vecs = [normalize(v) if np.dot(v, avg_dirs[cluster]) > 0 else normalize(-v) for v in vecs]\n",
    "        cluster_avgs.append(np.mean(aligned_vecs, axis=0))\n",
    "    \n",
    "    # Take the average of the two cluster averages and normalize the result\n",
    "    average_vector = normalize(np.mean(cluster_avgs, axis=0))\n",
    "    return average_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802920aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_vector_mean2(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e426f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_right_hand_angle(v1, v2, pn):\n",
    "    # some numpy bug (https://github.com/microsoft/pylance-release/issues/3277)\n",
    "    # cp = lambda v1, v2: np.cross(v1, v2)\n",
    "    # a = np.dot(cp(v1, v2), pn)\n",
    "    a = np.dot(np.cross(v1, v2), pn)\n",
    "    b = np.dot(v1, v2)\n",
    "    rha = np.arctan2(a, b)\n",
    "    return rha\n",
    "def unit_vector_mean3(vectors, cdir2, pn):\n",
    "    opposite_dir = get_right_hand_angle(vectors, cdir2, pn) < 0\n",
    "    vectors[opposite_dir] = -vectors[opposite_dir]\n",
    "    mean = np.median(vectors,axis=0)\n",
    "    normed_mean = mean / np.linalg.norm(mean)\n",
    "    return normed_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66f64fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_vector_mean3(vectors, cd2, pn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4c195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = plt.subplot(1,1,1,projection='3d')\n",
    "for vec in vectors:\n",
    "    plt.plot([0,vec[0]], [0,vec[1]], [0,vec[2]], c='blue')\n",
    "mean_vec = unit_vector_mean(vectors)\n",
    "plt.plot([0,mean_vec[0]], [0,mean_vec[1]], [0,mean_vec[2]], c='red')\n",
    "alt_mean_vec = unit_vector_mean2(vectors[:-4])\n",
    "plt.plot([0,alt_mean_vec[0]], [0,alt_mean_vec[1]], [0,alt_mean_vec[2]], c='green')\n",
    "ax.set_aspect(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a03af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_vector_mean(pns, cds1, cds2):\n",
    "    pns_to_use = get_right_hand_angle(pns, cds1[0], cds2[0]) > 0\n",
    "    if sum(pns_to_use) < len(pns_to_use)//2:\n",
    "        pns_to_use = np.logical_not(pns_to_use)\n",
    "    norm_mean = np.mean(pns[pns_to_use],axis=0)\n",
    "    normed_norm_mean = norm_mean / np.linalg.norm(norm_mean)\n",
    "    \n",
    "    cd1_dirs = get_right_hand_angle(cds1, cds2[0], normed_norm_mean) < 0\n",
    "    cds1[cd1_dirs] = -cds1[cd1_dirs]\n",
    "    cd1_mean = np.median(cds1,axis=0)\n",
    "    normed_cd1_mean = cd1_mean / np.linalg.norm(cd1_mean)\n",
    "    \n",
    "    cd2_mean = np.cross(normed_norm_mean, normed_cd1_mean)\n",
    "    normed_cd2_mean = cd2_mean / np.linalg.norm(cd2_mean)\n",
    "    if get_right_hand_angle(normed_cd1_mean, cd2_mean, normed_norm_mean) < 0:\n",
    "        normed_cd2_mean = -normed_cd2_mean\n",
    "    return normed_norm_mean, normed_cd1_mean, normed_cd2_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ff17f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cds = model._graph.x[5:10,cd_ids[0]:cd_ids[1]]\n",
    "cds1 = cds[:,:3]\n",
    "cds2 = cds[:,3:]\n",
    "pns = model._graph.x[5:10,pn_ids[0]:pn_ids[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnmean, cd1mean, cd2mean = pose_vector_mean(pns, cds1, cds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad57209",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = plt.subplot(1,1,1,projection='3d')\n",
    "for vec in pns:\n",
    "    plt.plot([0,vec[0]], [0,vec[1]], [0,vec[2]], c='grey')\n",
    "plt.plot([0,pnmean[0]], [0,pnmean[1]], [0,pnmean[2]], c='blue')\n",
    "plt.plot([0,cd1mean[0]], [0,cd1mean[1]], [0,cd1mean[2]], c='red')\n",
    "plt.plot([0,cd2mean[0]], [0,cd2mean[1]], [0,cd2mean[2]], c='orange')\n",
    "ax.set_aspect(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e6bcc0",
   "metadata": {},
   "source": [
    "## Time Different Matrix Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b82f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import timeit\n",
    "\n",
    "def increment_dict(sparse_dict, indices):\n",
    "    for index_tuple in indices:\n",
    "        sparse_dict[tuple(index_tuple)] += 1\n",
    "\n",
    "# Create random indices\n",
    "num_indices = 500\n",
    "shape = (50, 50, 50, 50)\n",
    "indices = np.random.randint(0, 50, size=(num_indices, 4))\n",
    "\n",
    "# Initialize the defaultdict and numpy array\n",
    "sparse_dict = defaultdict(int)\n",
    "dense_array = np.zeros(shape, dtype=int)\n",
    "\n",
    "# Time the increment_dict function\n",
    "dict_time = timeit.timeit(\"increment_dict(sparse_dict, indices)\",\n",
    "                          globals=globals(), number=10)\n",
    "\n",
    "# Time the np.add.at function\n",
    "numpy_time = timeit.timeit(\"np.add.at(dense_array, tuple(indices.T), 1)\",\n",
    "                           globals=globals(), number=10)\n",
    "\n",
    "print(f\"Dictionary increment time: {dict_time:.6f} seconds\")\n",
    "print(f\"NumPy array increment time: {numpy_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b662bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pympler import asizeof\n",
    "# Calculate memory usage\n",
    "dict_memory = asizeof.asizeof(sparse_dict)\n",
    "numpy_memory = sys.getsizeof(dense_array)\n",
    "\n",
    "print(f\"Dictionary memory usage: {dict_memory / 1024:.2f} KiB\")\n",
    "print(f\"NumPy array memory usage: {numpy_memory / 1024:.2f} KiB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6946792",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pympler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf99561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import timeit\n",
    "\n",
    "def dict_to_array(sparse_dict, shape):\n",
    "    dense_array = np.zeros(shape, dtype=int)\n",
    "    for index_tuple, value in sparse_dict.items():\n",
    "        dense_array[index_tuple] = value\n",
    "    return dense_array\n",
    "\n",
    "def array_to_dict(dense_array):\n",
    "    sparse_dict = defaultdict(int)\n",
    "    non_zero_indices = np.transpose(np.nonzero(dense_array))\n",
    "    for index_tuple in non_zero_indices:\n",
    "        key = tuple(index_tuple)\n",
    "        sparse_dict[key] = dense_array[key]\n",
    "    return sparse_dict\n",
    "\n",
    "# Create random indices\n",
    "num_indices = 10000\n",
    "shape = (50, 50, 50, 50)\n",
    "indices = np.random.randint(0, 50, size=(num_indices, 4))\n",
    "\n",
    "# Initialize the defaultdict\n",
    "sparse_dict = defaultdict(int)\n",
    "increment_dict(sparse_dict, indices)\n",
    "\n",
    "def conversion_and_add_at(sparse_dict, indices, shape):\n",
    "    dense_array = dict_to_array(sparse_dict, shape)\n",
    "    np.add.at(dense_array, tuple(indices.T), 1)\n",
    "    new_sparse_dict = array_to_dict(dense_array)\n",
    "    return new_sparse_dict\n",
    "\n",
    "# Time the conversion_and_add_at function\n",
    "conversion_time = timeit.timeit(\"conversion_and_add_at(sparse_dict, indices, shape)\",\n",
    "                                 globals=globals(), number=100)\n",
    "\n",
    "print(f\"Conversion and np.add.at time: {conversion_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c3b523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import timeit\n",
    "\n",
    "def dict_to_array(sparse_dict, shape):\n",
    "    dense_array = np.zeros(shape, dtype=int)\n",
    "    for index_tuple, value in sparse_dict.items():\n",
    "        dense_array[index_tuple] = value\n",
    "    return dense_array\n",
    "\n",
    "def array_to_dict(dense_array):\n",
    "    sparse_dict = defaultdict(int)\n",
    "    non_zero_indices = np.transpose(np.nonzero(dense_array))\n",
    "    for index_tuple in non_zero_indices:\n",
    "        key = tuple(index_tuple)\n",
    "        sparse_dict[key] = dense_array[key]\n",
    "    return sparse_dict\n",
    "\n",
    "# Create random indices\n",
    "num_indices = 10000\n",
    "shape = (50, 50, 50, 50)\n",
    "indices = np.random.randint(0, 50, size=(num_indices, 4))\n",
    "\n",
    "# Initialize the defaultdict\n",
    "sparse_dict = defaultdict(int)\n",
    "increment_dict(sparse_dict, indices)\n",
    "\n",
    "def conversion_and_add_at(sparse_dict, indices, shape):\n",
    "    start_time = timeit.default_timer()\n",
    "    dense_array = dict_to_array(sparse_dict, shape)\n",
    "    dict_to_array_time = timeit.default_timer() - start_time\n",
    "\n",
    "    start_time = timeit.default_timer()\n",
    "    np.add.at(dense_array, tuple(indices.T), 1)\n",
    "    add_at_time = timeit.default_timer() - start_time\n",
    "\n",
    "    start_time = timeit.default_timer()\n",
    "    new_sparse_dict = array_to_dict(dense_array)\n",
    "    array_to_dict_time = timeit.default_timer() - start_time\n",
    "\n",
    "    return dict_to_array_time, add_at_time, array_to_dict_time\n",
    "\n",
    "# Time the conversion_and_add_at function\n",
    "num_iterations = 1000\n",
    "total_dict_to_array_time = 0\n",
    "total_add_at_time = 0\n",
    "total_array_to_dict_time = 0\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    dict_to_array_time, add_at_time, array_to_dict_time = conversion_and_add_at(sparse_dict, indices, shape)\n",
    "    total_dict_to_array_time += dict_to_array_time\n",
    "    total_add_at_time += add_at_time\n",
    "    total_array_to_dict_time += array_to_dict_time\n",
    "\n",
    "print(f\"Total dict_to_array time: {total_dict_to_array_time:.6f} seconds\")\n",
    "print(f\"Total np.add.at time: {total_add_at_time:.6f} seconds\")\n",
    "print(f\"Total array_to_dict time: {total_array_to_dict_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a86ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import timeit\n",
    "\n",
    "def increment_dict(sparse_dict, indices):\n",
    "    for index_tuple in indices:\n",
    "        sparse_dict[tuple(index_tuple)] += 1\n",
    "\n",
    "def increment_torch_sparse(sparse_tensor, indices):\n",
    "    unique_indices, counts = np.unique(indices, axis=0, return_counts=True)\n",
    "#     for i, idx in enumerate(unique_indices):\n",
    "#         print(f\"{idx}: {counts[i]}\")\n",
    "    new_indices = torch.tensor(unique_indices.T, dtype=torch.long)\n",
    "    new_values = torch.tensor(counts, dtype=torch.int64)\n",
    "    new_sparse_tensor = torch.sparse_coo_tensor(new_indices, new_values, sparse_tensor.shape)\n",
    "    return sparse_tensor + new_sparse_tensor\n",
    "\n",
    "\n",
    "\n",
    "# Create random indices\n",
    "num_indices = 500\n",
    "shape = (50, 50, 50, 50)\n",
    "indices = np.random.randint(0, 50, size=(num_indices, 4))\n",
    "\n",
    "# Initialize the defaultdict, numpy array, and torch sparse tensor\n",
    "sparse_dict = defaultdict(int)\n",
    "dense_array = np.zeros(shape, dtype=int)\n",
    "sparse_tensor = torch.sparse_coo_tensor(torch.zeros((4, 0), dtype=torch.long), torch.tensor([]), size=shape)\n",
    "\n",
    "# Time the increment_dict function\n",
    "dict_time = timeit.timeit(\"increment_dict(sparse_dict, indices)\",\n",
    "                          globals=globals(), number=1000)\n",
    "\n",
    "# Time the np.add.at function\n",
    "numpy_time = timeit.timeit(\"np.add.at(dense_array, tuple(indices.T), 1)\",\n",
    "                           globals=globals(), number=1000)\n",
    "\n",
    "# Time the increment_torch_sparse function\n",
    "torch_sparse_time = timeit.timeit(\"increment_torch_sparse(sparse_tensor, indices)\",\n",
    "                                  globals=globals(), number=1000)\n",
    "\n",
    "print(f\"Dictionary increment time: {dict_time:.6f} seconds\")\n",
    "print(f\"NumPy array increment time: {numpy_time:.6f} seconds\")\n",
    "print(f\"Torch sparse tensor increment time: {torch_sparse_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a496c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pympler import asizeof\n",
    "# Calculate memory usage\n",
    "dict_memory = asizeof.asizeof(sparse_dict)\n",
    "numpy_memory = sys.getsizeof(dense_array)\n",
    "torch_memory = sys.getsizeof(sparse_tensor)\n",
    "\n",
    "print(f\"Dictionary memory usage: {dict_memory / 1024:.2f} KiB\")\n",
    "print(f\"NumPy array memory usage: {numpy_memory / 1024:.2f} KiB\")\n",
    "print(f\"Torch tensor memory usage: {torch_memory / 1024:.2f} KiB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
