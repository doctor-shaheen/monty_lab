{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999a21af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "from tbp.monty.frameworks.utils.logging_utils import (load_stats,\n",
    "                                                        check_rotation_accuracy,\n",
    "                                                        deserialize_json_chunks)\n",
    "from tbp.monty.frameworks.utils.plot_utils import (\n",
    "    plot_graph, \n",
    "    plot_feature_matching_animation,\n",
    "    show_one_step,\n",
    "    plot_evidence_at_step,\n",
    "    plot_sample_animation,\n",
    "    PolicyPlot,\n",
    "    plot_learned_graph,\n",
    "    plot_hotspots,\n",
    "    plot_sample_animation_multiobj,\n",
    "    plot_evidence_transitions,\n",
    "    plot_rotation_stat_animation,\n",
    "    plot_detection_stat_animation,\n",
    ")\n",
    "\n",
    "from tbp.monty.frameworks.utils.transform_utils import numpy_to_scipy_quat\n",
    "from tbp.monty.frameworks.utils.graph_matching_utils import (\n",
    "    detect_new_object_exponential,\n",
    "    detect_new_object_k_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d386e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fa3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8516b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify pre-training; determines point-cloud models that are visualized\n",
    "# General paths:\n",
    "pretrain_path = os.path.expanduser(\"~/tbp/results/monty/pretrained_models/\")\n",
    "log_path = os.path.expanduser(\"~/tbp/results/monty/projects/\")\n",
    "\n",
    "# Specific experiment paths:\n",
    "#pretrained_dict = pretrain_path + \"pretrained_ycb_v4/surf_agent_1lm_10similarobj/pretrained/\"\n",
    "pretrained_dict = pretrain_path + \"pretrained_ycb_v7/surf_agent_1lm_10distinctobj/pretrained/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976d01cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify whether curvature-informed or not\n",
    "exp_path = log_path + \"evidence_eval_runs/logs/base_10multi_distinctobj_dist_agent/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dab620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load some detailed stats\n",
    "# train_stats, eval_stats, _, lm_models = load_stats(exp_path,\n",
    "#                                                                 load_train=False,\n",
    "#                                                                 load_eval=True,\n",
    "#                                                                 load_detailed=False,\n",
    "#                                                                 pretrained_dict=pretrained_dict,\n",
    "#                                                                )\n",
    "\n",
    "# # Load just a single episode from detailed stats\n",
    "# det_path = os.path.join(exp_path, \"detailed_run_stats.json\")\n",
    "# detailed_stats = deserialize_json_chunks(json_file=det_path, episodes=[episode_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e75b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all detailed stats\n",
    "train_stats, eval_stats, detailed_stats, lm_models = load_stats(exp_path,\n",
    "                                                                load_train=False,\n",
    "                                                                load_eval=True,\n",
    "                                                                load_detailed=True,\n",
    "                                                                pretrained_dict=pretrained_dict,\n",
    "                                                               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca52f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d453d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in detailed_stats.keys():\n",
    "#     print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718bf043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # All keys for a particular episode\n",
    "# for key in detailed_stats[str(episode_num)].keys():\n",
    "#     print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22abe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Motor system keys\n",
    "# for key in detailed_stats[str(episode_num)][\"motor_system\"].keys():\n",
    "#     print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe944d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(detailed_stats[str(episode_num)][\"motor_system\"][\"action_details\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a24a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(detailed_stats[str(episode_num)][\"motor_system\"][\"action_sequence\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a9877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((detailed_stats[str(episode_num)][\"motor_system\"][\"action_sequence\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba719336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # SM Keys\n",
    "# for key in detailed_stats[str(episode_num)][\"SM_1\"].keys():  # All keys for a particular episode\n",
    "#     print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da4157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.shape(detailed_stats[str(episode_num)][\"SM_0\"][\"processed_observations\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2e21f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(detailed_stats[str(episode_num)][\"LM_0\"][\"lm_processed_steps\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2f4b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SM Keys\n",
    "# for item in detailed_stats[str(episode_num)][\"SM_0\"][\"raw_observations\"][100]:  # All keys for a particular episode\n",
    "#     print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb185b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step_num_temp=100\n",
    "# print(detailed_stats[str(episode_num)][\"SM_0\"][\"raw_observations\"][step_num_temp][\"rgba\"])\n",
    "# print(len(detailed_stats[str(episode_num)][\"SM_0\"][\"raw_observations\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0101a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize available keys in LM\n",
    "# for key in detailed_stats[\"1\"][\"LM_0\"].keys():\n",
    "#     print(key)\n",
    "    \n",
    "# # Locations : these are the locations of the sensor module *taking into account depth*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab4a312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize available keys\n",
    "# for key in lm_models[\"pretrained\"][0][\"mug\"]:\n",
    "#     print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80572ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_lm_model_stats(\n",
    "#     lm_models,\n",
    "#     episode,\n",
    "#     object_id,\n",
    "#     lm_index=0,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Get some basic stats about e.g. how many points each LM has in its object graph\n",
    "#     \"\"\"\n",
    "\n",
    "#     lm = \"LM_\" + str(lm_index)\n",
    "\n",
    "#     # Use point-cloud model of ground-truth object that is in the evironment\n",
    "#     # This is based on the *LM's model*, but always getting the ground-truth object,\n",
    "#     # i.e. regardless of whether the LM is successfully recognizing the object or not\n",
    "#     # Thus we can see if e.g. there is a difference in exploration depending on how\n",
    "#     # well known areas on the model are\n",
    "#     learned_model_cloud = lm_models[\"pretrained\"][lm_index][object_id].pos\n",
    "    \n",
    "#     return len(learned_model_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dc3498",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# for episode_iter in range(0,6):\n",
    "#     num_points = get_lm_model_stats(lm_models, episode=episode_iter,\n",
    "#                              object_id=detailed_stats[str(episode_iter)][\"target\"][\"target_object\"])\n",
    "#     print(\"\\nObject: \" + str(detailed_stats[str(episode_iter)][\"target\"][\"target_object\"]))\n",
    "#     print(num_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35aa5c5",
   "metadata": {},
   "source": [
    "### Plot learned graphs (no policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a3560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gather \"hot-spot\" data\n",
    "\n",
    "# for current_episode in range(3):\n",
    "#     # Mask based on successful jumps; in principle don't need to, but these will be more\n",
    "#     # interesting, because these are the locations we aim for when our pose estimates tend \n",
    "#     # to (at least presumably, although not by definition) be good\n",
    "#     # Need to mask based on what the MLH object was at the time (this information is available\n",
    "#     # already in the LM data)\n",
    "#     # --> ?need to transform based on the estimated pose at the time --> no shouldn't\n",
    "#     # need to because the target location will simply be in the reference frame of the object\n",
    "#     print(detailed_stats[str(current_episode)][\"motor_system\"][\"action_details\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94995f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learned_graph_with_bb(\n",
    "    detailed_stats,\n",
    "    lm_models,\n",
    "    episode,\n",
    "    object_id,\n",
    "    view=None,\n",
    "    noise_amount=0.0,\n",
    "    lm_index=0,\n",
    "    save_fig=False,\n",
    "    save_path=\"./\",\n",
    "    original_corners=[],\n",
    "    new_corners=[],\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot the graph learned for a particular object; does not include additional\n",
    "    visualizations of policy movements etc.\n",
    "\n",
    "    It differs from plot_graph in that the focus is on plotting a graph stored in an\n",
    "    LMs memory, where this is corrected to have the rotation and position in the\n",
    "    environment as was experienced during an episode.\n",
    "\n",
    "    Futhermore, there is the option to add noise, such that it is easy to visualize e.g.\n",
    "    the effect of noise in the location feature.\n",
    "\n",
    "    :param view: the elevation and azimuth to initialize the view at\n",
    "    \"\"\"\n",
    "\n",
    "    # Use point-cloud model of ground-truth object that is in the evironment\n",
    "    # This is based on the *LM's model*, but always getting the ground-truth object,\n",
    "    learned_model_cloud = lm_models[\"pretrained\"][lm_index][object_id].pos\n",
    "\n",
    "    converted_quat = numpy_to_scipy_quat(\n",
    "        detailed_stats[str(episode)][\"target\"][\"primary_target_rotation_quat\"]\n",
    "    )\n",
    "    object_rot = Rotation.from_quat(converted_quat)\n",
    "    \n",
    "    # Update original corners for the displacement\n",
    "    original_corners = np.array(original_corners) + np.array([0, 1.5, 0])\n",
    "\n",
    "    # Update orientation and position of the learned model to be in environmental\n",
    "    # coordinates\n",
    "    learned_model_cloud = (\n",
    "        object_rot.apply(learned_model_cloud)\n",
    "        + detailed_stats[str(episode)][\"target\"][\"primary_target_position\"]\n",
    "    )\n",
    "\n",
    "\n",
    "#     # Add optional noise; can be used to visualize e.g. how significant noise\n",
    "#     # in the sensory information might be\n",
    "#     noise_to_add = np.random.normal(0, noise_amount, size=np.shape(learned_model_cloud))\n",
    "#     learned_model_cloud = learned_model_cloud + noise_to_add\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    ax = plt.subplot(1, 1, 1, projection=\"3d\")\n",
    "\n",
    "    # Plot the learned graph of the object mapped on to where it actually is\n",
    "    # in the environment\n",
    "    ax.scatter(\n",
    "        learned_model_cloud[:, 0],\n",
    "        learned_model_cloud[:, 1],\n",
    "        learned_model_cloud[:, 2],\n",
    "        c=learned_model_cloud[:, 2],\n",
    "        alpha=0.3,\n",
    "    )\n",
    "    \n",
    "    ax.scatter(\n",
    "        original_corners[0][0],\n",
    "        original_corners[0][1],\n",
    "        original_corners[0][2],\n",
    "        c=\"red\",\n",
    "        alpha=0.8,\n",
    "        label=\"min_original\"\n",
    "    )\n",
    "\n",
    "    ax.scatter(\n",
    "        original_corners[1][0],\n",
    "        original_corners[1][1],\n",
    "        original_corners[1][2],\n",
    "        c=\"red\",\n",
    "        alpha=0.8,\n",
    "        label=\"max_original\"\n",
    "    )\n",
    "\n",
    "    ax.scatter(\n",
    "        new_corners[0][0],\n",
    "        new_corners[0][1],\n",
    "        new_corners[0][2],\n",
    "        c=\"green\",\n",
    "        alpha=0.8,\n",
    "        label=\"min_transformed\"\n",
    "    )\n",
    "\n",
    "    ax.scatter(\n",
    "        new_corners[1][0],\n",
    "        new_corners[1][1],\n",
    "        new_corners[1][2],\n",
    "        c=\"green\",\n",
    "        alpha=0.8,\n",
    "        label=\"max_transformed\"\n",
    "    )\n",
    "    \n",
    "    ax.set_aspect(\"equal\")\n",
    "    if view is not None:\n",
    "        ax.view_init(view[0], view[1])\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    print(\"figure saved at \" + save_path)\n",
    "    plt.legend()\n",
    "#     plt.savefig(\n",
    "#         save_path + f\"{episode}.png\",\n",
    "#         bbox_inches=\"tight\",\n",
    "#         dpi=300,\n",
    "#     )\n",
    "#     else:\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858f3da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "view_dic = dict(\n",
    "    mug=[-45,45],\n",
    "    spoon=[-45,90],\n",
    ")\n",
    "\n",
    "original_corners = [[-0.093004, -0.010495, -0.041427], [0.093004, 0.010495, 0.041427]]\n",
    "new_corners = [[0.04471411, 1.5414902,  0.0821906], [-0.04471411,  1.4585098,  -0.0821906]]\n",
    "\n",
    "\n",
    "episode_num=0 # 0 is mug, 6 is spoon\n",
    "target_id=detailed_stats[str(episode_num)][\"target\"][\"primary_target_object\"]\n",
    "\n",
    "# # Plot just the learned graph\n",
    "sns.set(font_scale = 1.0)\n",
    "plot_learned_graph_with_bb(detailed_stats, \n",
    "                    lm_models,  \n",
    "                    episode=episode_num,\n",
    "                    view=None,\n",
    "                    object_id=target_id,\n",
    "                  save_fig=True,\n",
    "                  original_corners=original_corners,\n",
    "                  new_corners=new_corners)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e823d9f",
   "metadata": {},
   "source": [
    "### Plot hot-spot areas visited by top-down policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4e8803",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "view_dic = dict(\n",
    "    mug=[25,-65],\n",
    "    spoon=[-45,90],\n",
    "    fork=[-45,110],\n",
    ")\n",
    "\n",
    "episode_num=0\n",
    "target_id=detailed_stats[str(episode_num)][\"target\"][\"target_object\"]\n",
    "\n",
    "# Plot just the learned graph\n",
    "sns.set(font_scale = 1.0)\n",
    "plot_hotspots(detailed_stats, \n",
    "                lm_models,  \n",
    "                episode_range=2,\n",
    "                view=view_dic[target_id],\n",
    "                object_id=target_id,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a1211",
   "metadata": {},
   "source": [
    "### Plot policy *animation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd2eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_dic = dict(\n",
    "    mug = [35,25],  # [45,-55]\n",
    "    spoon = [45,-75],\n",
    "    golf_ball = [45, 45],\n",
    ")\n",
    "zoom_dic = dict(\n",
    "    mug = 1.35,\n",
    "    spoon = 1.35,\n",
    "    golf_ball = 0.75,\n",
    ")\n",
    "\n",
    "episode_num = 0\n",
    "\n",
    "policy_plotter = PolicyPlot(\n",
    "        detailed_stats,\n",
    "        lm_models,\n",
    "        episode = episode_num,\n",
    "        object_id=detailed_stats[str(episode_num)][\"target\"][\"target_object\"],\n",
    "        agent_type=\"distant\",\n",
    "        jumps_used=True,\n",
    "        extra_vis=\"sensor_pose\",\n",
    "        lm_index=0,)\n",
    "\n",
    "policy_plotter.plot_animation()\n",
    "#policy_plotter.visualize_plot()\n",
    "\n",
    "#     view=view_dic[detailed_stats[str(episode_num)][\"target\"][\"target_object\"]],\n",
    "#     zoom=zoom_dic[detailed_stats[str(episode_num)][\"target\"][\"target_object\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d0f269",
   "metadata": {},
   "source": [
    "### Plot graph with policy, and *agent movements*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bea85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Good views for mug basic policy:\n",
    "[25,-150]\n",
    "[0,0]\n",
    "\"\"\"\n",
    "\n",
    "sns.set(font_scale = 1.0)\n",
    "episode_num=0\n",
    "temp_step=-1\n",
    "plot_policy_across_model(detailed_stats, \n",
    "                                lm_models,  \n",
    "                                episode = episode_num,\n",
    "                                step=30,\n",
    "                                object_id=detailed_stats[str(episode_num)][\"target\"][\"target_object\"],\n",
    "                                #view=[45,-80],\n",
    "                                #zoom=1.5,\n",
    "                                #extra_vis=\"sensor_pose\",\n",
    "                                #agent_step=40,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f0d057",
   "metadata": {},
   "source": [
    "### Camera observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efdea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_animation(patch_obs, viz_obs, semantic_obs, primary_target=\"\", save_bool=False):\n",
    "    \"\"\"Plot video of sampled oservations.\"\"\"\n",
    "    from IPython import display\n",
    "    from matplotlib import animation\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 4))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    marked_obs = viz_obs[0].copy()\n",
    "    marked_obs[29:35, 29:35] = [0, 0, 255, 255]\n",
    "    im1 = plt.imshow(marked_obs)\n",
    "    ax1.set_xticks([]), ax1.set_yticks([])\n",
    "    plt.title(\"Overview (Zoomed out)\")\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    im2 = plt.imshow(patch_obs[0])\n",
    "    ax2.set_xticks([]), ax2.set_yticks([])\n",
    "\n",
    "#     num_steps = len(all_obs)\n",
    "#     plot_obs = all_obs[0]\n",
    "#     for obs in all_obs[1:]:\n",
    "#         # obj_obs = obs[np.where(obs[:, 3] > 0)]\n",
    "#         plot_obs = np.append(plot_obs, obs, axis=0)\n",
    "#     res = plot_obs.shape[0] // num_steps\n",
    "#     obj_obs = plot_obs[\n",
    "#         np.where((plot_obs[:res, 3] > 0))  # & (plot_obs[:res, 2] < 0))\n",
    "#     ]\n",
    "\n",
    "#     scale_obs = plot_obs[np.where((plot_obs[:, 3] > 0))]\n",
    "#     p1 = ax3.scatter(\n",
    "#         -obj_obs[:, 1],\n",
    "#         obj_obs[:, 0],\n",
    "#         obj_obs[:, 2],\n",
    "#         c=obj_obs[:, 2],\n",
    "#         vmin=min(scale_obs[:, 2]),\n",
    "#         vmax=max(scale_obs[:, 2]),\n",
    "#     )\n",
    "\n",
    "#     ax3.set_xticks([]), ax3.set_yticks([]), ax3.set_zticks([])\n",
    "#     ax3.set_xlabel(\"x\", labelpad=-10)\n",
    "#     ax3.set_ylabel(\"y\", labelpad=-10)\n",
    "#     ax3.set_zlabel(\"z\", labelpad=-10)\n",
    "\n",
    "#     plot_zoom = 0.07\n",
    "#     means = np.mean(plot_obs, axis=0)\n",
    "#     ax3.set_xlim([-means[1] - plot_zoom, -means[1] + plot_zoom])\n",
    "#     ax3.set_ylim([means[0] - plot_zoom, means[0] + plot_zoom])\n",
    "#     ax3.set_zlim([means[2] - plot_zoom, means[2] + plot_zoom])\n",
    "#     ax3.view_init(110, 0)\n",
    "\n",
    "    def init():\n",
    "        # avoid calling 0 twice\n",
    "        pass\n",
    "\n",
    "    def animate(i):\n",
    "        marked_obs = viz_obs[i].copy()\n",
    "        marked_obs[29:35, 29:35] = [0, 0, 255, 255]\n",
    "        im1.set_array(marked_obs)\n",
    "        im2.set_array(patch_obs[i])\n",
    "        plt.title(\"primary_target: \" + primary_target + \"\\nstepwise_target: \" + semantic_obs[i])\n",
    "\n",
    "#         point_idx = int((i + 1) * res)\n",
    "#         obj_obs = plot_obs[\n",
    "#             np.where(\n",
    "#                 (plot_obs[:point_idx, 3] > 0)  # & (plot_obs[:point_idx, 2] < 0)\n",
    "#             )\n",
    "#         ]\n",
    "#         p1._offsets3d = (-obj_obs[:, 1], obj_obs[:, 0], obj_obs[:, 2])\n",
    "#         p1.set_array(obj_obs[:, 2])\n",
    "\n",
    "        return (ax1,)\n",
    "\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, animate, frames=len(viz_obs), init_func=init\n",
    "    )\n",
    "    video = anim.to_html5_video()\n",
    "    html = display.HTML(video)\n",
    "    display.display(html)\n",
    "    \n",
    "    if save_bool:\n",
    "        anim.save(\n",
    "            \"viewfinder_gif.gif\",\n",
    "            writer=\"imagemagick\",\n",
    "            dpi=300,\n",
    "        )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce0d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_num=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9e5e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(detailed_stats[str(episode_num)][\"SM_0\"][\"raw_observations\"][step_num_temp][\"rgba\"])\n",
    "# print(len(detailed_stats[str(episode_num)][\"SM_0\"][\"raw_observations\"]))\n",
    "\n",
    "viz_obs = []\n",
    "patch_obs = []\n",
    "\n",
    "# assert (len(detailed_stats[str(episode_num)][\"SM_0\"][\"raw_observations\"]) == len(detailed_stats[str(episode_num)][\"SM_1\"][\"raw_observations\"]), \"Different number of obs\")\n",
    "\n",
    "for ii in range(len(detailed_stats[str(episode_num)][\"SM_0\"][\"raw_observations\"])):\n",
    "    \n",
    "    viz_obs.append(detailed_stats[str(episode_num)][\"SM_1\"][\"raw_observations\"][ii][\"rgba\"])\n",
    "    patch_obs.append(detailed_stats[str(episode_num)][\"SM_0\"][\"raw_observations\"][ii][\"rgba\"])\n",
    "\n",
    "viz_obs = np.array(viz_obs) #[:100]\n",
    "patch_obs = np.array(patch_obs) #[:100]\n",
    "semantic_obs = detailed_stats[str(episode_num)][\"LM_0\"][\"stepwise_targets_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f307b324",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_sample_animation_multiobj(patch_obs, viz_obs, semantic_obs, primary_target=detailed_stats[str(episode_num)][\"target\"][\"primary_target_object\"], save_bool=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d308095a",
   "metadata": {},
   "source": [
    "### Visualize Evidence Across Object Transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feec36f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_stats[str(episode_num)][\"LM_0\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f86e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_stats[str(episode_num)][\"LM_0\"][\"stepwise_targets_list\"]\n",
    "len(detailed_stats[str(episode_num)][\"LM_0\"][\"stepwise_targets_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abe57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_num=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f2a0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(detailed_stats[str(episode_num)][\"LM_0\"][\"evidences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f810dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mapping = {\n",
    "'golf_ball':\"grey\", 'dice':\"black\", 'spoon':\"steelblue\", 'strawberry':\"red\", 'banana':\"yellow\", 'bowl':\"darkviolet\", 'potted_meat_can':\"lightblue\", 'mug':\"sienna\", 'c_lego_duplo':\"hotpink\", 'mustard_bottle':\"gold\"\n",
    "}\n",
    "detection_cmapping = {\n",
    "    \"true_positive\" : \"blue\",\n",
    "    \"false_positive\" : \"red\",\n",
    "    \"false_negative\" : \"grey\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ec2ebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e94965",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# K-absolute method\n",
    "detection_params_dict = dict(\n",
    "    detection_threshold=-1.0,\n",
    "    k=2,\n",
    "    reset_at_positive_jump=False,\n",
    ")\n",
    "\n",
    "plot_evidence_transitions(episode_num, detailed_stats[str(episode_num)][\"LM_0\"], \n",
    "                          detection_fun=detect_new_object_k_steps,\n",
    "                          detection_params_dict=detection_params_dict,\n",
    "                          primary_target=detailed_stats[str(episode_num)][\"target\"][\"primary_target_object\"],\n",
    "                          color_mapping=color_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2decff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential_method\n",
    "detection_params_dict = dict(\n",
    "    detection_threshold=-1.0,\n",
    "    decay_rate=2,\n",
    "    reset_at_positive_jump=False,\n",
    ")\n",
    "plot_evidence_transitions(episode_num, detailed_stats[str(episode_num)][\"LM_0\"], \n",
    "                          detection_fun=detect_new_object_exponential,\n",
    "                          detection_params_dict=detection_params_dict,\n",
    "                          primary_target=detailed_stats[str(episode_num)][\"target\"][\"primary_target_object\"],\n",
    "                          color_mapping=color_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b222eca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# K-absolute method with reset when we get positive evidence\n",
    "detection_params_dict = dict(\n",
    "    detection_threshold=-1.0,\n",
    "    k=2,\n",
    "    reset_at_positive_jump=True,\n",
    ")\n",
    "plot_evidence_transitions(episode_num, detailed_stats[str(episode_num)][\"LM_0\"], \n",
    "                          detection_fun=detect_new_object_k_steps,\n",
    "                          detection_params_dict=detection_params_dict,\n",
    "                          primary_target=detailed_stats[str(episode_num)][\"target\"][\"primary_target_object\"],\n",
    "                          color_mapping=color_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e8e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_at_thresholds(detection_fun, detection_param):\n",
    "    thresholds_to_try = np.linspace(-5.0, 0, 50)\n",
    "    tpr_results = []\n",
    "    fpr_results = []\n",
    "\n",
    "    for threshold in thresholds_to_try:\n",
    "    #     print(\"Trying threshold :\" + str(threshold))\n",
    "        temp_tpr=[]\n",
    "        temp_fpr=[]\n",
    "        for episode_num in range(10):\n",
    "            tpr, fpr = plot_evidence_transitions(episode_num, detailed_stats[str(episode_num)][\"LM_0\"], \n",
    "                                  detection_fun=detection_fun,\n",
    "                                 detection_threshold=threshold,\n",
    "                                  detection_param=detection_param,\n",
    "                                  primary_target=detailed_stats[str(episode_num)][\"target\"][\"primary_target_object\"],\n",
    "                                  color_mapping=color_mapping)\n",
    "            if tpr is not None:\n",
    "                temp_tpr.append(tpr)\n",
    "            if fpr is not None:\n",
    "                temp_fpr.append(fpr)\n",
    "        # Get performance of this threshold averaged across multiple episodes,\n",
    "        # but only if there is some meaningful performance to log\n",
    "    #     print(\"Threshold results:\")\n",
    "    #     print(temp_tpr)\n",
    "    #     print(temp_fpr)\n",
    "        if len(temp_tpr) > 0 and len(temp_fpr) > 0:\n",
    "            tpr_results.append(np.mean(temp_tpr))\n",
    "            fpr_results.append(np.mean(temp_fpr))\n",
    "    return tpr_results, fpr_results\n",
    "# print(tpr_results)\n",
    "# print(fpr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89401933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try some different decay values\n",
    "# 0 corresponds to no decay, 30 corresponds to only looking at the most recent step\n",
    "decay_rate_vals = [0, 0.1, 0.25, 0.5, 2.0, 30]\n",
    "k_vals = [1, 2, 4, 6, 8, 10]\n",
    "k_reset_vals = [2, 4, 6, 8, 10, 20]  # No point evaluating at k==1, as equivalent to without reset\n",
    "k_norm_vals = [2, 4, 6, 8, 10, 20]  # Again, k==1 is equivalent to other versions\n",
    "\n",
    "param_results = {}\n",
    "for decay_rate in decay_rate_vals:\n",
    "    \n",
    "    tpr_results, fpr_results = evaluate_at_thresholds(detection_fun=detect_new_object_exponential,\n",
    "                                                      detection_param=decay_rate)\n",
    "    param_results[\"decay_\" + str(decay_rate) + \"_tpr\"] = tpr_results\n",
    "    param_results[\"decay_\" + str(decay_rate) + \"_fpr\"] = fpr_results\n",
    "\n",
    "# for k in k_vals:\n",
    "#     tpr_results, fpr_results = evaluate_at_thresholds(detection_fun=detect_new_object_k_steps,\n",
    "#                                                       detection_param=k)\n",
    "#     param_results[\"k_\" + str(k) + \"_tpr\"] = tpr_results\n",
    "#     param_results[\"k_\" + str(k) + \"_fpr\"] = fpr_results\n",
    "\n",
    "# for k_reset in k_reset_vals:\n",
    "#     tpr_results, fpr_results = evaluate_at_thresholds(detection_fun=k_abs_with_reset_detect_new_object,\n",
    "#                                                       detection_param=k_reset)\n",
    "#     param_results[\"k_reset_\" + str(k_reset) + \"_tpr\"] = tpr_results\n",
    "#     param_results[\"k_reset_\" + str(k_reset) + \"_fpr\"] = fpr_results\n",
    "\n",
    "# for k_norm in k_norm_vals:\n",
    "#     tpr_results, fpr_results = evaluate_at_thresholds(detection_fun=k_norm_with_reset_detect_new_object,\n",
    "#                                                       detection_param=k_norm)\n",
    "#     param_results[\"k_norm_\" + str(k_norm) + \"_tpr\"] = tpr_results\n",
    "#     param_results[\"k_norm_\" + str(k_norm) + \"_fpr\"] = fpr_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cf4bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_rate_vals = [0.5]\n",
    "for decay_rate in decay_rate_vals:\n",
    "    plt.plot(param_results[\"decay_\" + str(decay_rate) + \"_fpr\"], param_results[\"decay_\" + str(decay_rate) + \"_tpr\"], label=\"Decay \" + str(decay_rate), alpha=0.5)\n",
    "\n",
    "# for k in k_vals:\n",
    "#     plt.plot(param_results[\"k_\" + str(k) + \"_fpr\"], param_results[\"k_\" + str(k) + \"_tpr\"], label=\"k-val \" + str(k), linestyle=\"dotted\", alpha=0.5)\n",
    "\n",
    "# for k_reset in k_reset_vals:\n",
    "#     plt.plot(param_results[\"k_reset_\" + str(k_reset) + \"_fpr\"], param_results[\"k_reset_\" + str(k_reset) + \"_tpr\"], label=\"k_reset-val \" + str(k_reset), linestyle=\"dashed\", alpha=0.5)\n",
    "    \n",
    "# for k_norm in k_norm_vals:\n",
    "#     plt.plot(param_results[\"k_norm_\" + str(k_norm) + \"_fpr\"], param_results[\"k_norm_\" + str(k_norm) + \"_tpr\"], label=\"k_norm_-val \" + str(k_norm), linestyle=\"solid\", alpha=0.5)\n",
    "    \n",
    "plt.plot([0, 1.0], [0, 1.0], color=\"grey\", linestyle=\"--\", alpha=0.5, label=\"random classifier\")\n",
    "plt.title(\"New-Object Detection\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.xlim(0,1.0)\n",
    "plt.ylim(0,1.0)\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.plot(thresholds_to_try, thresholds_to_try, color=\"grey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80fc335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checking the equivalence of decay rate and k at appropriate parameters\n",
    "# decay_rate=30\n",
    "# plt.plot(param_results[str(decay_rate) + \"_fpr\"], param_results[str(decay_rate) + \"_tpr\"], label=\"Decay \" + str(decay_rate), alpha=0.5)\n",
    "\n",
    "# k=1\n",
    "# plt.plot(param_results[str(k) + \"_fpr\"], param_results[str(k) + \"_tpr\"], label=\"k-val \" + str(k), linestyle=\"dotted\", alpha=0.5)\n",
    "    \n",
    "# plt.plot([0, 1.0], [0, 1.0], color=\"grey\", linestyle=\"--\", alpha=0.5, label=\"random classifier\")\n",
    "# plt.title(\"New-Object Detection\")\n",
    "# plt.ylabel(\"TPR\")\n",
    "# plt.xlabel(\"FPR\")\n",
    "# plt.xlim(0,1.0)\n",
    "# plt.ylim(0,1.0)\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# #plt.plot(thresholds_to_try, thresholds_to_try, color=\"grey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d5cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for all objects\n",
    "for episode_num in range(10):\n",
    "    plot_evidence_transitions(episode_num, detailed_stats[str(episode_num)][\"LM_0\"], \n",
    "                              detection_fun=detect_new_object_exponential,\n",
    "                              detection_threshold=-1.0,\n",
    "                              detection_param=30,\n",
    "                              primary_target=detailed_stats[str(episode_num)][\"target\"][\"primary_target_object\"],\n",
    "                              color_mapping=color_mapping,\n",
    "                              save_fig_path=\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd3be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebb90be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
